{
  "hash": "c6adb21e02b854b722fd2e650ccbb53e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"\"\nformat: html\neditor: visual\n---\n\n\n\n\nMethod 2 Window Pane-LASSO-Best Subset\n\n## Loading dataset\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(gsheet)\ntrials_weather = gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1SIb-z-c2R4DiNAV8AcFAn7UPjlQe5t5bPxxl1tMdQwA/edit?usp=sharing\")\n```\n:::\n\n\n\n\nThe Window Pane method is used to summarize weather variables over specific time windows relative to an event (for example, sowing or flowering). Instead of analyzing daily values, the variable is aggregated (using mean, sum, or another statistic) over fixed intervals, such as 1–10 days after sowing, 11–20 days, and so on. This reduces noise and allows identification of critical time windows that may influence disease development.\n\n## Creating window\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(rlang)\n# Define the intervals\nwindow_size <- 10\nstart_days <- -5:(90 - window_size + 1)\n\nintervals <- lapply(start_days, function(s) c(s, s + window_size - 1))\n\n#List of variables to summarize\nvars <- c(\"GWETROOT\", \"GWETTOP\", \"T2M\", \"T2M_MAX\", \"T2M_MIN\", \"T2M_RANGE\", \"RH2M\", \"PRECTOTCORR\",\"T2MDEW\", \"WS2M\",'PS',\"ALLSKY_SFC_SW_DWN\", \"CLRSKY_SFC_SW_DWN\", \"e_s\",\"e_a\",\"VPD\", \"TDD\",\"T2M_night\",\"LWD_hours\",\"CLOUDCOVER\")\n\n# Function to compute a summary variable for a period\nsummarize_period <- function(data, var, period, label) {\n var_sym <- sym(var)\n  start_day <- period[1]\n  end_day <- period[2]\n  period_name <- paste0(var, \"_\", label)\n\ndata %>%\n   dplyr::select(study, days, !!var_sym) %>%\n    group_by(study, days) %>%\n    summarise(value = mean(!!var_sym, na.rm = TRUE), .groups = \"drop\") %>%\n    pivot_wider(names_from = days, values_from = value) %>%\n    mutate(!!period_name := rowMeans(across(as.character(start_day:end_day)), na.rm = TRUE)) %>%\n    dplyr::select(study, !!period_name) %>%\n    mutate(study = factor(study))\n}\n\n# Create all variable summaries for all intervals\n# Function to format day labels\nformat_day <- function(day) {\n  if (day < 0) paste0(\"n\", abs(day)) else as.character(day)\n}\n\n# Create all variable summaries for all intervals with clean labels\nsummaries <- cross2(vars, intervals) %>%\n  imap(~ {\n    var <- .x[[1]]\n    period <- .x[[2]]\n    label <- paste0(format_day(period[1]), \"_\", format_day(period[2]))\n    summarize_period(\n      data = trials_weather,\n      var = var,\n      period = period,\n      label = label\n    )\n  })\n\n# Create epidemic base\nepidemic <- trials_weather %>%\n  dplyr::select(study, epidemic) %>%\n  group_by(study) %>%\n  slice(1) %>%\n  mutate(study = factor(study))\n\n# Join all summaries and epidemic\nfinal_df <- reduce(summaries, left_join, by = \"study\") %>%\n  left_join(epidemic, by = \"study\")\nfinal_df2 <- na.omit(final_df)\n\nlibrary(writexl)\nwrite_xlsx(final_df2, \"final_df2.xlsx\")\n```\n:::\n\n\n\n\n## LASSO\n\n(Least Absolute Shrinkage and Selection Operator)\n\nThe LASSO regression is a variable selection and regularization technique. It applies a penalty to the size of the regression coefficients, forcing some of them to become exactly zero. This way, LASSO automatically selects the most important predictors (weather variables and time windows) while avoiding overfitting. It is especially useful when there are many correlated predictors.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(glmnet)\nweather_vars <- trials_weather %>% \n  dplyr::select(c(-lon, -lat, -LON, -LAT, -YEAR, -MM, -DOY, -YYYYMMDD, -days, -inc, -source, -sowing, -municipality, -DD))\nset.seed(123)\nlambdas <- 10^seq(2, -3, by = -.1)\n\ny <- final_df2 %>%\n  dplyr::select(epidemic) %>%\n  as.matrix()\n\n\n\nX <- final_df2%>%\n  ungroup() |> \n  dplyr::select(-epidemic, - study) %>%\n  as.matrix()\n\n\n# Setting alpha = 1 implements lasso regression\nlasso_reg_1week <- cv.glmnet(X, y,\n  alpha = 0.5,\n  family = \"binomial\",\n  lambda = lambdas,\n  standardize = TRUE,\n  nfolds = 5\n)\nplot(lasso_reg_1week)\n\n# Best\nlambda_best_1week <- 0.06\n\nlambda_best_1week\n\nlasso_model_1week <- glmnet(X,\n  y,\n  alpha = 1,\n  family = \"binomial\",\n  lambda = lambda_best_1week,\n  standardize = TRUE\n)\ncoef(lasso_model_1week)\ncoefs = coef(lasso_model_1week)\n\nnonzero_coefs <- data.frame(\n  variable = rownames(coefs),\n  coefficient = as.numeric(coefs)\n) %>%\n  filter(abs(coefficient) > 1e-6) %>%   # ignora valores muito próximos de zero\n  arrange(desc(abs(coefficient)))\n\n\nassess.glmnet(lasso_model_1week,\n  newx = X,\n  newy = y\n)\n```\n:::\n\n\n\n\n## Best Subset Selection\n\nThe Best Subset Selection method evaluates all possible combinations of predictors and identifies the subset that provides the best model fit according to a chosen criterion (such as AIC, BIC, or adjusted R²). Unlike LASSO, which imposes shrinkage, Best Subset exhaustively searches for the optimal combination of variables, although it may become computationally intensive when the number of predictors is large.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(bestglm)\n\n# Extract non-zero coefficient names (exclude intercept)\nlasso_coefs <- coef(lasso_model_1week)\nselected_vars <- rownames(lasso_coefs)[which(lasso_coefs != 0)]\nselected_vars <- selected_vars[!selected_vars %in% c(\"(Intercept)\")]\nselected_vars\n\n\ndata_v <- data.frame(final_df)\ndat <- data_v %>%\ndplyr::select(epidemic,selected_vars) %>%\n  mutate(y = epidemic) %>%\n  dplyr::select(-1)\ndat <- data.frame(dat)\n\nbest.logit2 <- bestglm(\n  Xy = dat,\n  family = binomial,\n  IC = \"BIC\",\n  TopModels = 50000,\n  method = \"exhaustive\",\n  nvmax = 10\n)\nsummary(best.logit2$BestModel)\nbest.logit2$Subsets\n\n\nf <- data.frame(best.logit2$Subsets)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}